{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royaad/AIC/blob/main/%5BSolution%5D_Project_Machine_Translation_Deployment_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Translation Deployment Using Gradio\n",
        "© 2023, Zaka AI, Inc. All Rights Reserved."
      ],
      "metadata": {
        "id": "xiC75uo6u_Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "SBTvDTzBv293"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "4_j1ZzS3v6N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0IARXAX1e1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6c0ac4-f9c8-4d00-dabf-bb472020097e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# hide TF warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import numpy as np\n",
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "import string, re, pickle, logging\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning git"
      ],
      "metadata": {
        "id": "vAcLqZ7uv-SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Your Zaka\n",
        "#cloning git repo\n",
        "!git clone https://github.com/royaad/AIC\n",
        "#changing working directory\n",
        "%cd AIC/Week_10/data"
      ],
      "metadata": {
        "id": "0-M7cFxTPpqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef6deba-ac57-45c9-f2e2-d212331eab5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIC'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 90 (delta 26), reused 7 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), 7.59 MiB | 2.93 MiB/s, done.\n",
            "/content/AIC/Week_10/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Translator Class"
      ],
      "metadata": {
        "id": "s4s-spsRyGJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator:\n",
        "\n",
        "  def __init__(self, model_directory='./'):\n",
        "    logging.info(\"Translator Initialized\")\n",
        "    self.directory = model_directory\n",
        "    self.model = load_model(model_directory+'EN_FR_Translator.h5')\n",
        "    logging.info(\"Model is loaded!\")\n",
        "\n",
        "  def predict(self, in_sentence, in_language='EN', out_language='FR', Max_Length=21):\n",
        "    in_sentence = self.text_cleaner(in_sentence)\n",
        "    X = self.Encoder(in_sentence, in_language, Max_Length)\n",
        "    Y = np.ravel(np.argmax(self.model.predict(X, verbose=0), axis=2))\n",
        "    out_sentence = self.logits_to_text(Y, out_language)\n",
        "    out_sentence = out_sentence.replace('<pad>', '')\n",
        "    return out_sentence.strip()\n",
        "\n",
        "  def text_cleaner(self, sentence):\n",
        "    sentence = sentence.lower()\n",
        "    translation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    sentence = re.sub(r\"(?<!\\d)[- \\'](?!\\d)\", ' ', sentence)\n",
        "    sentence = sentence.translate(translation_table)\n",
        "    return sentence\n",
        "\n",
        "  def Encoder(self, sentence, language, length=21):\n",
        "    #integer encode sequences\n",
        "    seq = self.text_to_seq(sentence, language)\n",
        "    #pad sequences with 0 values\n",
        "    seq = pad_sequences([seq], maxlen=length, padding='post')\n",
        "    return seq\n",
        "\n",
        "  def logits_to_text(self, logits, language):\n",
        "\n",
        "    word_index = self.word_index_dict(language)\n",
        "    index_word = dict(zip(word_index.values(), word_index.keys()))\n",
        "    index_word[0] = '<pad>'\n",
        "\n",
        "    return ' '.join([index_word[prediction] for prediction in logits])\n",
        "\n",
        "  def word_index_dict(self, language):\n",
        "    if language == 'EN':\n",
        "      pickle_dict = open(self.directory + \"EN_dict.pickle\",\"rb\")\n",
        "      dictionary = pickle.load(pickle_dict)\n",
        "      return dictionary\n",
        "    elif language == 'FR':\n",
        "      pickle_dict = open(self.directory + \"FR_dict.pickle\",\"rb\")\n",
        "      dictionary = pickle.load(pickle_dict)\n",
        "      return dictionary\n",
        "    else:\n",
        "      print('Input Language Does Not Exist')\n",
        "\n",
        "  def text_to_seq(self, sentence, language):\n",
        "    sentence = sentence.split()\n",
        "    seq = []\n",
        "    word_index = self.word_index_dict(language)\n",
        "    #OOVs are dropped\n",
        "    for x in sentence:\n",
        "      try:\n",
        "        seq.append(word_index[x])\n",
        "      except:\n",
        "        pass\n",
        "    return seq"
      ],
      "metadata": {
        "id": "I8RwV5mMyg8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Translate Function"
      ],
      "metadata": {
        "id": "JxvvVU3ezUHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading model\n",
        "def translate(sentence):\n",
        "  model = Translator()\n",
        "  translation = model.predict(sentence)\n",
        "  return translation"
      ],
      "metadata": {
        "id": "PXB4MiOsxhPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"She is driving the truck.\"\n",
        "\n",
        "translation = translate(input)\n",
        "print(translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QpTW8UqNtC",
        "outputId": "6362cb01-41ee-46b7-ccf9-740b93d784e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elle conduit le camion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Gradio Interphace"
      ],
      "metadata": {
        "id": "5T_sNnCGfUtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn = translate, inputs = gr.components.Textbox(lines=2, placeholder='Enter your English sentence here\\n(15 words max)'), outputs = 'text')"
      ],
      "metadata": {
        "id": "aKC6TorlfOuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "x5F45DF2frIO",
        "outputId": "213a7183-c7ac-4edc-f130-628f7a570d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f63fbd57f30e520550.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f63fbd57f30e520550.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interface.close()"
      ],
      "metadata": {
        "id": "A_kQ--f3gjNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543d29b0-84cb-49ec-812d-072aa4396b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}